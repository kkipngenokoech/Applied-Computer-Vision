{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 's' to capture the image...\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mimread(filename, cv2\u001b[38;5;241m.\u001b[39mIMREAD_GRAYSCALE)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Step 1: Capture the reference image\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m reference_image \u001b[38;5;241m=\u001b[39m \u001b[43mcapture_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m, in \u001b[0;36mcapture_image\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCapture Image\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# Press 's' to save\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimwrite(filename, frame)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.11.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def capture_image(filename=\"captured_face.jpg\"):\n",
    "    \"\"\" Capture an image from the webcam and save it \"\"\"\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    print(\"Press 's' to capture the image...\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "\n",
    "        cv2.imshow(\"Capture Image\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('s'):  # Press 's' to save\n",
    "            cv2.imwrite(filename, frame)\n",
    "            print(\"Image saved successfully!\")\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    return cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Step 1: Capture the reference image\n",
    "reference_image = capture_image()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "def extract_features(image, method=\"SIFT\"):\n",
    "    \"\"\" Extract features using SIFT, ORB, or BRIEF and return a flattened feature vector \"\"\"\n",
    "    if method == \"SIFT\":\n",
    "        extractor = cv2.SIFT_create()\n",
    "    elif method == \"ORB\":\n",
    "        extractor = cv2.ORB_create()\n",
    "    elif method == \"BRIEF\":\n",
    "        fast = cv2.FastFeatureDetector_create()\n",
    "        extractor = cv2.xfeatures2d.BriefDescriptorExtractor_create()\n",
    "        keypoints = fast.detect(image, None)\n",
    "        keypoints, descriptors = extractor.compute(image, keypoints)\n",
    "        return keypoints, descriptors\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported feature extraction method\")\n",
    "\n",
    "    keypoints, descriptors = extractor.detectAndCompute(image, None)\n",
    "\n",
    "    if descriptors is not None:\n",
    "        # Ensure PCA components are valid\n",
    "        n_samples, n_features = descriptors.shape\n",
    "        n_components = min(n_samples, n_features, 40)  # Dynamically choose max 20 features\n",
    "\n",
    "        if n_components > 1:\n",
    "            pca = PCA(n_components=n_components)\n",
    "            descriptors = pca.fit_transform(descriptors)\n",
    "        \n",
    "        # Take mean of descriptors to form a single feature vector\n",
    "        feature_vector = np.mean(descriptors, axis=0) if descriptors is not None else np.zeros(n_components)\n",
    "\n",
    "        return keypoints, feature_vector\n",
    "    else:\n",
    "        return keypoints, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Extract features from the captured image\n",
    "method = \"SIFT\"  # Change to \"ORB\" or \"BRIEF\" to test\n",
    "reference_keypoints, reference_features = extract_features(reference_image, method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored feature vector using SIFT: (40,) dimensions\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store features\n",
    "stored_features = {\n",
    "    \"method\": method,\n",
    "    \"features\": reference_features\n",
    "}\n",
    "\n",
    "print(f\"Stored feature vector using {method}: {reference_features.shape} dimensions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 's' to capture the image...\n",
      "Image saved successfully!\n",
      "Euclidean Distance: 1.249654724233551e-05\n",
      "Cosine Similarity Score: -0.2074752300977707\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def match_features(new_features, stored_features, method=\"euclidean\"):\n",
    "    \"\"\" Compare features using Euclidean Distance or Cosine Similarity \"\"\"\n",
    "    if method == \"euclidean\":\n",
    "        distance = euclidean(new_features, stored_features)\n",
    "        return distance  # Lower value means closer match\n",
    "    elif method == \"cosine\":\n",
    "        similarity = cosine_similarity([new_features], [stored_features])[0][0]\n",
    "        return similarity  # Higher value means closer match\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported matching method\")\n",
    "\n",
    "# Capture a new image for comparison\n",
    "comparison_image = capture_image(filename=\"comparison_face.jpg\")\n",
    "\n",
    "# Extract features from the new image\n",
    "comparison_keypoints, comparison_features = extract_features(comparison_image, method)\n",
    "\n",
    "# Compare using Euclidean Distance\n",
    "euclidean_distance = match_features(comparison_features, stored_features[\"features\"], method=\"euclidean\")\n",
    "print(f\"Euclidean Distance: {euclidean_distance}\")\n",
    "\n",
    "# Compare using Cosine Similarity\n",
    "cosine_score = match_features(comparison_features, stored_features[\"features\"], method=\"cosine\")\n",
    "print(f\"Cosine Similarity Score: {cosine_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
